What is NoSQL?

Introduction

The point of this module is to get you acquainted with the qualities that the various NoSQL databases have in common.

There are a number of different NoSQL databases, they break down into separate subcategories

List out a number of those common traits.

The way NoSQL databases handle
database consistency
indexing
NoSQL queries
computation algorithm called MapReduce, an approach employed by a number of NoSQL databases, understand how it works, at a high level.
partitioning pattern that many NoSQL databases use called sharding.


NoSQL Common Traits


Non-Relational

NoSQL is it's a little bit of a misnomer, quite frankly. NoSQL databases, actually a couple of them will support SQL, structured query language as an interface to query the data inside the database.

But what you will find is that really no NoSQL database is relational. The whole idea of normalized data modeling and joining of tables really doesn't exist in the NoSQL world.

If you've done any work with databases going back into the '80s were file based, it's almost as if that model has made a bit of comeback here.

However, it -- there really are two traits of NoSQL databases that are the ones you should really commit to memory.

non-relational approach is one of them.
These databases can be either schema free or at least what I might call schema flexible
plain English
as you go from one record to the next record within the same table
you may find that the structure of those records actually differs.
It may differ just at a detailed level
It may differ in a very fundamental way


Eventual Consistency
This is the way NoSQL databases deal with the idea of taking instruction from you and acting on it, or not acting on it, as the case may be.
When you go to add a new record or, or update an existing one, most NoSQL databases will process that request very quickly.
But processing the request and actually implementing the request are two different things. So a number of these products actually delay the work of doing the update and in the case where things are kind of clustered, and we'll talk about that in a second, even if the work is done in a relatively short timeframe on one member of the cluster, it may take a while to reach some of the others.

Now the advantage of this is that you tell the database what you want to do, it gives you back control very quickly and you go onto the next thing. What you give up in return for that, in return for that, you know, very sort of limited burden of, of waiting for processing to complete is that the changes you've asked for may take a while to propagate out, that's really the tradeoff.

The theme of tradeoffs is constant one when you look at NoSQL and when you're coming from a different database model, most specifically relational.


Open Source
You'll also find that most NoSQL databases are open source.
Many of them come from Apache Open Source Projects.

Developers who work themselves with open source tools and languages tend to be more interested in using NoSQL as the repository for their applications than those coming from more proprietary kind of enterprise stacks.



Distributed
Most NoSQL databases are also distributed databases, now this actually a really important point because although relational databases can also act in a very distributed way, there, there tends to be a lot of work involved in that, and that tends to be something that gets set up in special circumstances. With NoSQL databases, that's actually fairly standard, I would say. And the distributed nature is interesting because it means that the data can be split amongst multiple nodes in a cluster, i.e. servers in a grouping of servers, but what it also means is that the data on one server may well be replicated on another, that provides for fault tolerance, it also provides for a certain geographic distribution of data and, and allows applications that are, geographically dispersed to operate in a more responsive way at the edge of the networks.



Web Scale
This dovetails into this idea of web scale applications.

web scale is a term that gets bandied about, not rigorously defined
but what I would say with respect to NoSQL is that there are a number of applications out there, they're large, they're public, they tend to be consumer facing and the databases that underlie them to be rather unsophisticated.

However, the sheer volume of users overall and, and also concurrent users ends up creating such a demand, such a burden on the system that although the needs are relatively simple, those simple needs must be met very, very quickly. So, although, you know, the database looks innocent to begin with, the fact that it's so big and needs to be so responsive creates requirements that are not run of the mill at all, but are actually very special. And NoSQL databases tend to be optimized to that particular scenario, or that, that set of scenarios.



Big Internet Companies
Due to the nature of web scale requirements you'll find that a lot of NoSQL databases have their heritage in projects at big internet companies, companies like Yahoo and Google and Facebook, even LinkedIn.

All of these are sites that have, you know, had to pioneer the idea of building technologies that work well with these web scale scenarios. So it's, it's not surprising that a lot of these, a lot of these products kinds of emanate from those, those kinds of companies.




Consistency, indexes

So let's speak a little bit further about the whole notion of database consistency and how NoSQL handles it.

And in order to really appreciate that, there's a, there's an overall rubric for, for all databases and the kinds of features and functionality that they need to juggle.

It's important to understand how that works so that we can understand how relational databases respond to that and how NoSQL databases respond to it.

And it will also be useful if we can produce an example, a real world example where the same approach to consistency that NoSQL databases take is used as well.

consistency in NoSQL databases is important because NoSQL databases tend to be distributed.
when you have a distributed database with different nodes in a cluster, the question of whether data is replicated between those nodes is consistent, is bound to come up.



### CAP Theorem
CAP stands for
consistency
availability
partition tolerance.

Of these three things, any given database can really only excel at two of them.

relational databases tend to excel at consistency and partition tolerance
NoSQL databases tend to excel at availability and partition tolerance.



### ACID
ACID stands for
atomicity
consistency
isolation
durability


Relational databases make ACID guarantees,
they can take multiple operations and glom together into a single atomic transaction
they keep things consistent
they can isolate different transactions from each other
durability of course is, is guaranteed

NoSQL does not offer that.

NoSQL values availability over consistency.
uses a scheme called eventual consistency:
when requests come into the database to create records or update them, those may not be acted upon immediately.
They may be buffered, they may be delayed and even once they've taken place in one node in a distributed database, it may take a while for the other nodes to become consistent.

Relational databases consistency is, is of primary importance, so we'll guarantee that but, you know, that takes a while. So after you issue your instructions to me, I may keep you waiting while I make everything consistent

what NoSQL databases say is we'll, we'll get the consistency eventually, but meanwhile, we'll give control back to you because we're going to buffer things. So if we're going to buffer things, then the instructions you give us, we can take and, and process very quickly 'cause we're not actually going to act on them right away. Now, this whole notion that things will eventually become consistent, if you're coming from the relational world, it may seem kind of preposterous, but if you think about it, there are real life situations where it works.


### Example
If you think about the domain name system on the internet and the fact that small groups of users each have their own domain name server, then you have a real world example of where eventual consistency works. If you run your own blog or small website and you change your service provider, your hosting provider, you're going to need to go in and make an update to your host record in your GMS entry where you'll need to change the IP address. And when you do that, you'll find that some of your friends will see your new blog almost immediately. For others, it may take a while and for those who are further afield geographically, it may take longer still. But eventually, within a day or two, everybody will be directed to your new site.

So, there's a case where you can get in and get out very quickly, right? When you update your DNS record, that happens rather instantaneously. What you're not caught waiting for is, is for everybody to be updated. You can rest assured that eventually they will be and in effect, you make your peace with the idea that the update will not be immediate, but you judge that to be a fair tradeoff for being able to get your work done very quickly.

And NoSQL databases really apply the same logic, they say if you're building big web scale sites, the most important thing is that the rights you make to the database from your point of view are handled very quickly so you can get onto the next one and the next one and the next one. And you're willing to trade off that speed, or you're willing to trade off immediate consistency with the speed of the operation.




### Indexing
Now indexing with NoSQL databases has an equally, oh, perhaps counter intuitive quality to it if you're coming from the relational world

most NoSQL databases are indexed by the key of the table.

There's a name for indexes that aren't based on the key and those are called secondary instances. And only some NoSQL databases support those.

And of course if you think about the way NoSQL databases are liberal with respect to schema, it sort of makes sense.

How can you index on something that you can't even be certain is there?
Even if it is there for every single record in a database, the fact that it doesn't have to be makes the whole notion of secondary indexes a bit indeterminate.



What also happens though with NoSQL databases is that oftentimes, even though you're limited to a primary key for your index, that index will automatically be a cluttering index which means that the table will be physically ordered according to it.


In the case of H base, H base sits on top of Hadoop's Distributed File System and that file system actually only allows files to be appended to. You, you do not have the ability to gain random access to a given file. So, that seems like it's incredibly inconvenient, but the way H base kind of mitigates that is it says, all rights are going to be logged and buffered. We're going to batch them up and then at various intervals, we're going to take all the, all the logged and buffered rights and we're going to process them and we're going to rebuild the file that contains the table completely from scratch. So we're going to take care of all those rights. We're going to reorder the table and not only that, but, you know, that when you did the rights, you got control back really quickly. So you're going to get control back quickly and eventually when we process those writes, you're going to be able to query the table very quickly because it's going to be physically sorted.






Queries, MapReduce, Sharding


So the next thing that's important to talk about with respect to NoSQL databases is how they handle queries. And even the term query needs to be used a little bit loosely.


By and large, NoSQL databases don't actually support a query language.
The whole notion of a declarative query over the data actually doesn't exist.

Instead, you really need to think of the data as files,
the files hold all of the rows or records that you created
To process and, and determine what's inside of those files we create a procedural program that will actually loop through those files
This loop stacks things up and executes some conditional logic and then give you back the answers that you need.

Sometimes SQL is supported as a query language.
But most NoSQL databases tend to use actual imperative code, rather than declarative query.


### MapReduce
A lot of them also use a coding approach called MapReduce.

MapReduce is about writing code that has two functions in it.

The first function implements the map step
The map step splits the overall query and dispatches it according to the distributed nature of the NoSQL database. Those individual queries will execute in parallel on different nodes in the cluster.
they're going to put their results in an intermediate spot, according to the key of each row in those results.

The second function implements the reduce step
This function will execute at each of those locations where all the rows for a given key exist, it will merge and reduce those interim results, to return a series of values in a result set



This is very typical of Hadoop.
Hadoop has two things in it. It has the Hadoop Distributed File System that we already talked about and it has a map reduce engine as well. There is a, a class of NoSQL database called wide column stores, we'll talk about that more in the next module. And one of the databases in that category that we've actually already mentioned is H base.

H base and Hadoop tend to be used together and lots of MapReduce code that is executed by Hadoop tends to execute on H base tables.





Amazon web services has a specific service within it called Elastic MapReduce

Elastic MapReduce is a cloud provisioned set of servers running Hadoop and what's interesting about Amazon's MapReduce offering is that it can read and write data from a number of different data sources.

It can read and write from
	Dynamo DB, which itself a NoSQL offering.
	S3
	even relational databases


So the thing to remember about MapReduce is it's not database. It is a processing approach that takes files as input and produces a file as output and because a lot of NoSQL databases really are just manipulating individual files, most of their data tables are valid inputs and outputs for a MapReduce engine.

There is something called Hive, which is in effect, an add on to Hadoop.
Hive offers a sequel like abstraction over MapReduce. This can work against Hive's own tables, which are their own special variety of HDFS files and it can also be used over H base. So here you have a very specific example where a NoSQL database, namely H base can in fact be queried with a variance of SQL through this product called Hive.







### Sharding
Sharding is a partitioning pattern

The whole notion of NoSQL databases being distributed goes hand in hand with this.

Sharding is a database partitioning scheme where each server in a cluster ends up storing separate partitions.
This means your database isn't just split over numerous physical disks, but each partition is actually managed on a different server.
And that, in effect, means that each is autonomous.

However, most NoSQL databases with their sharding facility supports so-called fan out queries
where you submit one query to, you know, a master node in the cluster and it takes care of pushing that out, often using MapReduce to all the nodes in the cluster, has all the smaller queries run in parallel and, and then puts everything back together again.


Partitions can also be duplicated and so you get replication out of sharding as well, which is good for disaster recovery.
This is also the whole reason why the question of, of database consistency comes up and is so important.

Because the shards aren't just on separate servers, but can be distributed geographically as well, those different servers in a cluster don't need to be on the same network or really even anywhere close to each other.

The distributed nature gives you an advantage in that you can put the different shards to close to people who are specific edges of the network and it's almost as if it, it acts as a content distribution network.

That, in turn, can help the MapReduce efficiency
because if you're going to split up a query and tell a specific node in a server to work on some of it, if the data that that node needs to work on is local to it, that is not only -- you're not only getting the advantage of executing the query in parallel over multiple nodes, but you're also going to optimize network traffic by making sure that the different nodes are actually processing local data.











NoSQL Technology Breakdown
Introduction, Key-Value Stores

Examine each of the four major subcategories of no SQL databases.

We'll see what distinguishes the categories from each other, and we'll also see that there are certain concepts that remain consistent throughout them.

We're going to start with the most foundational and general purpose category of no SQL databases and that is the so-called key-value stores.

We'll move on then to a genre called wide column stores that you'll find in use at many of the larger internet companies.

We'll look at so-called document stores or document-oriented databases, and in this case we'll have a demo of one particular document store called CouchDB.

We'll finish up with a look at graph databases which are a category of no SQL database that are especially well suited to tracking relationships between entities.

You'll see throughout all four of these categories that the mechanics of key-value pairs to store values and look them up present themselves over and over, and it ends up being a very important no SQL concept overall.




### key-value Stores
The most common, the most foundational, and also the most general purpose.

They're not necessarily the most popular because key-value Stores tend to be, I suppose, less exotic that some of the others and they tend to fit so many different purposes.
But don't let their lack of perceived popularity dissuade you from using them, they are especially well suited to a great variety of applications.


key-value stores actually contain tables
tables have rows just like a relational database,
but within the row, in effect, what you're getting is a big dictionary or associative array of keys and values.
And the schema can differ between rows completely.

A hallmark of no SQL databases is this liberal approach with respect to schema, but there are different degrees of freedom here. And with key-value stores that freedom is really absolute.
Each row can have a completely different schema. The only thing that is guaranteed is that each will have a unique ID.

You'll see that key-value stores are common Cloud platforms, and perhaps the fact that they work best in terms of their being general purpose no SQL databases would explain this.

But two important examples of key-value store no SQL databases are
Amazon's SimpleDB
the table storage option on Window's Azure

A new offering from Amazon web services is called DynamoDB
Amazon's original Dynamo key-value store database. Now despite what I've said about the popularity of key-value stores and the prevalence of wide column stores and large internet companies, Amazon has done a lot of business on this Dynamo key-value store database.

Dynamo was really proprietary to Amazon and not offered externally. DynamoDB changes all of that, and it's in effect the new version of Dynamo and it's available as a service.



So here's a diagrammatic explanation of how key-value stores work.
[Databases\NoSQL\Key-ValueStore.png]

As I said they do have real databases and they do have real tables.
A table row has an ID and key-value pairs.

In a table called Customers
Here's a row
First name: Andrew
Last name: Brust
Address: 123 Main Street
Last Order: 1501.

We'll see what Last Order is in a moment.

Here's another one
First name: Jane
Last name: Doe
Address: 123 Elm Street
Last Order: 1502

and in this case, I kept the schema the same
because in point of fact often you're going to do just that.

However, you do have the ability to completely vary this. And if we imagine the address as being a little bit more elaborate than just a street address, we know that different countries have different address formats and it might make sense to have different address fields depending on the country that the customer lives in.

In a table called Orders

Here's a row
RowID: 1501
Price: 300 USD
Item1: 52134
Item2: 24457

Another row
RowID: 1502
Price: 2500 GBP
Item1: 98456
Item2: 59428


Now the thing to remember here is this is not like a relational database where storing that value somehow enlists these two tables in a join or in a foreign key constraint. There are no foreign keys. There are no joins. The only reason that Last Order number is there is so that later on when we write imperative code and we want to get the most recent order for Andrew Brust, we'll be able to do that simply by doing a search on the orders table until we find the row with ID 1501. So there are a lot of kind of manual mechanics involved when you move into the world of no SQL.



### Document Stores

Document stores have databases rather than tables and then interestingly rather than rows they have documents.

Now what are documents?
Well, typically documents are JSON objects,
a JavaScript Object Notation Object.

And as such, each document has properties because an object has properties and those properties have values.

Now at first flash that sounds an awful lot like the key-value store

But keep in mind that values can be drawn from a wide array of things here. So the values can be simple scaler values. They can also be arrays. They can be links to documents in other databases and they themselves can be JSON objects. So you can have an object containing an object which kind of equates to a document containing a document which is kind of a nice option for hierarchal storage. And you can have attachments as well; you can actually attach files to these documents. When you put that together, all those things together, and you combine it with the fact that old versions, every single old version of a document is retained, you realize that document stores end up working pretty well for content management applications.

And with that in mind the whole idea of calling these things documents starts to make sense.


Now some people don't view document stores as a category in their own right. They look at them as specialized key-value stores, and in fact they are literally speaking specialized key-value stores. But you can make that same argument for almost every no SQL technology.

The point is that document stores do end up getting used in a certain sub-class of applications. I think they qualify to have full subcategory status.

They end up being very popular with developers and in a second you're going to see why because
as it turns out, document stores have a very close affinity with web servers, of all things. So startups really like to use these guys and the people who fund startups like them too.

The biggies are CouchDB and MongoDB, and here are the logos for those.



Here's a diagram
[Databases\NoSQL\DocumentStore.png]

If you look at the number property and the street property in Document ID 101 or 102 in the customer's database on the left, you'll see that in effect that is a document within the document. It's a gradient rectangle just like its parent is. And so at the customer level, you have a property called "Address. " Address, itself, points to an object and the object has properties called "Number" and "Street. " We've also got a most recent "Order" property in a subdocument, and it in turn is linked to a document in the Orders database. And that is a real codified link not merely the storage of a key-value. And then the rest of it follows pretty naturally from that.

You see the Orders database has very little about it that's especially fancy.


Application Oriented
Now I mentioned that document stores are very popular with developers and let's look at some reasons why. Well first of all, it turns out each document is addressable by its own URI or more colloquially known as a URL.
CouchDB actually supports a full rest interface and in effect works with HTTP. It behaves an awful lot like a web server in point of fact in terms of creating data, pulling data down, fetching it, updating it, all the standard HTTP verbs are used.
This category of database is very geared towards JavaScript and JSON. We've already seen that documents are JSON objects, and what you don't know but I'll tell you now is that both CouchDB and MongoDB use JavaScript as their native language.
In CouchDB you can even create JavaScript functions called "View Functions" which get their own unique URI's mapped to them and they return HTML. So if you think of the way PHP works or if you think of the way the old active server pages worked in the Microsoft stack where you're writing script code that runs on the server and produces HTML programmatically, in effect CouchDB has the same notion and the ability to work on its intrinsic database. In this you can build entire applications in the database itself; you don't have to but you can.



Demo: CouchDB

All right. Let's take a look at a real document database, and in this case it's CouchDB. We are right now in a utility which, in keeping with the theme of couches is called "Futon. " And Futon let's you manage your databases and actually do data entry and data maintenance all inside of a nice browser-based application. Notice we have a link up here on the upper left to create a database, and if we click that and supply a name for the database, boom, it's done. That's all there is to it. Of course we don't have any documents in it, so let's go ahead and take care of that. We'll click "New Document. " And notice automatically we get an ID field and we get a unique string that will become the ID for this document. We could overwrite that with our own value if we wanted to, but I'm going to go ahead and leave it right there. And I'm going to add a new field, and this new field is going to be called "Title. " Imagine we're going to make a little database to capture our media library. And imagine we have a copy of the book "Catcher in the Rye. " Now because it's a book, we kind of want to record that, so we'll create a field called "Type of Media" and we'll put "Book. " And because it's a book we'll create one more field called "Number of Pages, " and I looked this up online and the current edition of the book has 214 pages. Now I can save each of these edits. That doesn't actually save the document though, so I'm going to go ahead and click "Save Document. " And we're all set. Now let's create another document. Let's go back in the bread crumb trail to the database's page and then let's add a new document. Let's add a new field. Now notice that even if I want to stay 100% consistent in structure, I still have to do that manually. Every new document is a brand new clean slate. So I'm going to use a structure that is similar but not identical to the last document. We're going to have "Title" and in this case it's going to be "Citizen Kane, " and of course that's a movie so we'll have a "Type of Media" field again and we'll put "Film" as the type of media. We'll tab out of there and we'll add one more field. And because this is a film, we're going to go ahead and put the duration down and that's 119 minutes. Now notice I put the unit in the value here, whereas before the unit was in effect in the name of the field. And that may strike you somewhat inconsistent and I suppose it is. But because the database is going to be very geared to kind of serving up content, I'm okay with that. As long as I don't need to do any kind of analytics on this number, I'm all right with the fact that it ends up kind of being a real text value. So let's go ahead and save this document and let's go back to the database's page, and now you see we have both documents in there. Let's click on this guy and let me click on the "Source" tab over here, and you'll see that in fact the way the document is actually serialized out is as a JavaScript object. And in fact, we could've come in here and entered the document in this fashion as long as we were careful to put unique ID's in for ID and Revision. Speaking of revision, if we go back over here -- And in fact I didn't even have to do that, but imagine I look this up again and discovered it's not 119 minutes but it's 120. Now notice that the revision number ends in "CDE76. " When I save the document, though, watch what happens. The revision number changed and this link lit up. Now we have the ability to go and look at both versions. So if I click "Previous Version" we see CDE76 and 119, and if I click "Next Version" we see the 120 minutes and 213A. So that's a nice demo for something we've built from scratch. I had already built another database and it also has just two content documents in it, but it has a little more richness. I've actually created a couple of documents here that represent data from the Pluralsight catalogue. So I've created a document for Matt Milner's "Developing OData Clients" course. I created a "Key Words" field and I've actually set this up as an array. So notice the square brackets open and close; basically, this is a string array. And I've also created a field called "Metadata" that is itself an object. And this is data pasted straight from the site so we have the duration, the level, and the release date in the "Metadata" field. If we go to source, notice this really is one JavaScript object but within it, right, it has an array down here for keywords and it's also got the metadata which is itself an object, so all of that works very nicely, very fluidly, and very easily. If we go back to the home page for the database and click this document, you'll notice also I've added an attachment. I did that by clicking "Upload Attachment. " And what this attachment is, is it is actually a listing of all the modules and the clips for Keith's course from the website printed out to a PDF. So now the notion of calling these things document databases really makes sense, and you can imagine that if something about this course and its metadata, or otherwise, were updated, I'd have the ability to go in there and fix it up. So that's good. Now there's one more document in here. And this one's interesting because if you look at its ID, right, it's got a very kind of specific format to it. It starts with the word "underscore Design" and then it has a slash and the word "Example. " If I click on that, you'll see there's some interesting stuff going on here. There's ID and revision just like there was before, but there is a field called "Shows" that has it's own kind of subfield and then there's another field called "Views. " And if I take you over to the source, you'll see what's really going on here which is that we've got a bunch of JavaScript in here. And the JavaScript is stored as a value of a key called "Map" which belongs to an object called "All" which is itself a key inside of the view's object. So lots of nesting, and we're storing code as data. Now notice what this map function does. And by the way the reason it's called "Map" is because even in CouchDB, you can do map and reduce. Reduce is optional, though, so this map step, this is really easy. Right? What this is doing is it's saying, "Given the document, I'll put its ID and its course. " So if you call this we're going to get the ID and the course for everything in the database. This guy does something a little bit differently; although, in our case it will yield the same result. It'll output the ID and the course if the string. net is contained within the keywords array property of the document. So we use the JavaScript index of function as long as it's greater than zero, we can go ahead and see that document. And then I did exactly the same thing, but in this case instead for all. NET courses, it's just for those with the keyword "Data Access. " So if we ran this thing, we should see just the OData course. And if we run. NET, we should be able to see both. We also have a show function. We talked about those. This one's called "Summary" and notice it actually intersperses HTML with data, so we're going to get back the course, the instructor, and the keywords, and we've got labels for each. And the course title and the instructor will be inside of H1 tag so they'll be in larger text. So that's pretty neat now that we have this in here; that's lovely. The question is, how do we run it? And this is where I get to show you this notion of being able to navigate to things directly. I didn't show it to you for documents, but I'm going to show it to you now for views and for show functions. Let's flip over to Notepad here and what you'll see is that we have a bunch of links. Now they all start with the same route which is simply the local host IP address and the default port for CouchDB which is 5984, then the name of the database verbatim, then underscore design to get to a design document, the name of the design document. Then within that design document, we want to get to "View" and specifically we want to get to the view called ". NET. " This one, as a reminder, should give us both courses. And we'll hit it and that's exactly what happened. We got "Developing OData Clients" and we got introduction to see (inaudible). NET. Now this is JavaScript output. Ordinarily this is something we'd request programmatically and process programmatically, but because CouchDB is so HTTP and web-based we can just do this through URL's in the browser. It's no problem. Let's go back here and look at the "Data Access" one instead, and in this case we should just see the OData course. And that's exactly what we've got. And then finally let's look at how we get to the show function. This part's the same as the other two, but because it's a show function we use "underscore Show" instead of "underscore View, " then the name of the show function. And because show functions typically will operate on a single document, we have to give it the ID of the document. And this is, I believe, the OData course's ID. I can double check that for you. Let's go back over here. Let's go to Pluralsight and C5C is the OData Client's course. So we'll come over here and we'll copy this last link -- This is the last part of our demo -- into the address bar. We'll hit "Enter" and boom, there it is. We have the title and the instructor data within the H1 tags, and we've got our keywords in regular text. We can view the source, and notice we got exactly what we asked for. So, pretty neat stuff. Again, very document oriented, very web-oriented, and that's why these databases are so popular with developers. ( Silence )



Wide Column Stores

As with key-value stores, wide column stores have tables and they have columns within the tables.

What is a little bit different, though, is that wide-column stores take a hybrid approach mixing the declarative consistence game of relational databases with the key-value pair based and totally variable schema of key-value stores.

The way that hybrid works is that you need to declare so-called column families as part of a consistent schema. But the column families kind of work somewhat like categories of columns, and within a column family you can have different columns in each row. The wide-column stores tend to be the databases that are most foundational at large sites. Now we've already talked about how Dynamo, which is a key-value store, is in wide use at Amazon. And so that's an exception. But if you take a look at a wide column store called Big Table, which is proprietary at Google that Google tends to use with his MapReduce computation engine for working with large data sets, you start to understand why wide column stores might be used in these situations at large sites. And then because Big Table and MapReduce were, and are, proprietary to Google but because Google also published details of each in academic papers, the open-source world came together led by Yahoo and created a open-source version of MapReduce called Hadoop and an open source of Big Table called H Base. Meanwhile over at Facebook, they created something called Cassandra which is also a wide column store database. It uses slightly different vocabulary, though, calling column families "Super Columns" and calling tables "Super Column Families. " Now given the pedigree of these different databases from these large internet companies and given that they're all matched with MapReduce engines, because Cassandra can also be used with Hadoop, these end up being the databases that by and large are used in big data applications. Again, Dynamo is a bit of an exception as it can be used for big data applications as well. But very often you'll see Hadoop and H Base used. Obviously at Google they'd be using MapReduce and Big Table, and it is possible, as I said, to put Hadoop and Cassandra together as well. Here are some logos just so you can get a visual sense and, again, map back to this conversation when you come across some of these logos. And now let's get a quick diagrammatic sense of how all this works. Once again, we have real tables and within tables we have rows. Now notice that this row corresponds very closely to the first row we saw in the key-value store table called "Customers" and the columns are almost the same. We've got "First Name" and "Last Name. " We've broken "Street" into two different columns just to kind of prove a point, and we've got a "Last Order" field as well. And then notice that every column must be part of a super column, so we've created super columns for name, address, and orders. And, again, the second row here has the same schema as the first, but if we wanted to we could add, for example, a middle name column for Customer 202 here without also having to have that in 101. And then we've got our orders as well, and we've done pretty much the same thing here. These are exactly the same columns that we had before but we've placed them under a super column called "Pricing" and another one called "Items. "



Graph Databases

Great. Let's talk about graph databases. They're the subcategory of no SQL databases that work especially well for tracking relationships. As such, they're great for social network applications or just about anything where relationships are important. And relationships can be thought of in an expansive way because, you know, one relationship is about possession or containment, and with that being the case you can pretty much portray just about any data relationship in a graph database. Vocabulary you need to be familiar with includes nodes and edges. And as you'll see on the diagram, a node can be pictured like an oval and edges are the lines connecting the ovals together. The edges are kind of like joins between rows in a table. Nodes can also have properties and values, so once again the whole notion of key-value pairs crops again and again and again. And a popular graph database is Neo4j. Here's it's logo. Now let's take a look at a diagram to get a deeper understanding of how graph databases work. You start with a database and then you have an object, like Andrew Brust. I haven't specified a bunch of properties and values here, but that's okay because part of what we want to portray is just that we can track relationships between things. Now in this case I'm specifying that Andrew Brust has an address- relationship with the address 123 Main Street, New York, New York 10014. He also has a friend-relationship with George Washington. And let's think of some other social networking scenarios; maybe Andrew commented on a photo by Joe Smith or sent an invitation to Jane Doe. Maybe Andrew also made a purchase of some sort and that order ID was 252. The total price was 300 dollars, and it had a couple of items in it, a blue dress and a red shirt. So notice some of these ovals have lots of properties and values. Some of them don't have any but because they have edges that point to other objects that do have properties and values, it's still all quite mappable.




Where is NoSQL a Killer App?
Intro and content management

We will now map a specific NoSQL subcategory onto that scenario and in that way we'll be able to see which one fits best.

That'll actually achieve a couple of purposes.
First of all, it will reinforce our understanding of what the different subcategories are.
Second of all, you know, by making a specific case for a subcategory, we'll be making a very strong general case for NoSQL at large.

The scenarios that we'll want to look at are Content Management applications, Product Catalogs, and really Product Catalogs stand for an awful lot of things. They stand for really any application where you have objects with meta data, especially when the meta data varies and you need to track that.
We'll talk about Social networking applications.
We'll talk about Big Data applications and then we'll kind of talk about everything else. We have a catchall Miscellaneous scenario as well.


### Content Management
Document databases work really well here.

Think about what happens with content management;
You have the content itself and the content also has meta data.
You may need to know whether it's a, you know, a video asset or a photographic asset and how large it is, and so on and so forth.

So Key-Value pairs can work really well to store the meta data.

If the content can be represented as text, let's say it's HTML, let's say it's XML, well, then you can use Key-Value pairs to store the text-based content -- the content in the text-based situation as well. Attachments can store -- can be used to store file-based or binary content. So this isn't just about scalar values and things that can be represented as text. We can deal with binary content; we can deal with, you know, we can deal with entire files including photographs and videos just by attaching them to the document. And the versioning and URI addressability obviously help quite a bit. If we have every version of a given document, that means we can easily roll back. And that means it's very easy to browse, view, and modify what's going on because we can navigate to -- we can navigate to individual documents in a straightforward way. CouchDB gets called a "Web database" Which is to say it's a database that works really well for Web applications. And as we've already seen in the prior module, you can actually embed those applications in the database itself. Now what does Web app mean in this case? Well, I would encourage you to think of websites. Many of them consumer facing and not enterprise line of business applications that happen to run in a browser. If you think of something like EverNote, you're in for a very good use case for document databases and their ability to store content.



Product catalogs and social

Product Catalogs.

Here again it's all about the meta data. The thing about products and again, pretty much anything that might need to be cataloged in general, is that the items tend to have attributes that are common and then they tend to have specific attributes. They could be category or subcategory specific. They could even be item specific. So here are some examples of some common meta data items. Things like the product ID, and the name, the description, and the price. And then about 4 different class-specific ones. You could have flavor; you could have color in the case of, you know, food or apparel. In the case of technology items, you might be measuring things like resolution or clockspeed.

Both Key-Value Stores and Wide Column Stores work well here.

Key-Value Stores probably work best of all because since Wide Column Stores require that at least column families be declared. Key-Value Stores give you flexibility and of course as you're adding items to your catalog, you may be adding items of a very different sort at some point, at which case your schema would need to be modified. And really the whole purpose of using NoSQL databases is not to have to deal with the disruption of modified schema.



Social applications
Social applications tend to work very well with graph databases. We've discussed that as well. Think of the different kinds of things that involve objects and the relationships between them. You've got social networks; you've got your group of followers; you've got memberships of different groups. But also things for comments, and likes/favorites, and messages; right? The objects don't have to be people. The objects can be things and the things have different relationships to each other, especially in threaded interactions because one can be a reply to the other. And, you know, meanwhile both can belong to the thread itself. So tracking those different relationships that each object has ends up working well because you can have lots of edges. Also works well for membership and ownership. We talked about the group membership right up there. But if you want to keeps tabs on, you know, what objects are owned by whom, or what projects or what tasks are owned by whom, you've got a good case for a graph database. When you think of things like a relational database that tries to track which employees report to which other employees, you get somewhat awkward structures like a self-join. Or if you want to know which members are in which group and which groups contain which members, when you have many-to-many relationships like that that gets difficult to portray in a relational database. You end up having to create special tables just to portray those joins. But with graph databases, this kind of -- this kind of correspondence between things is modeled very easily.


Big Data, miscellaneous

Big Data applications.
We already discussed how Wide Column Stores work well here. Key-Value Stores can work as well. And we specifically mentioned that Amazon's DynamoDB or Dynamo is their Key-Value Store and they use it in a lot of Big Data scenarios. MapReduce is designed for this. MapReduce is all about, you know, taking a big query and chopping it up into pieces, dispatching those pieces out to different nodes in a cluster, and then using a reduce step to aggregate everything back together into a single result set. And MapReducer processors tend to work best with Wide Column data stores. You'll see that Hadoop and Hbase come up a lot here. So again Hadoop is the open source version of Google's MapReduce and Hbase is the open source version of Google's Big table, both of which draw lots of inspiration from the papers that Google had presented publicly on their 2 products. The fact that sharding is so important in NoSQL databases works really well for Big Data. If I can shard a database then I can deal with pretty much any size. I have ways to back the data up and I also have ways to split the data up. And the "append-only" simply means that I can deal with my writes very fast. I will have a lot of work in terms of rewriting the table to get it sorted properly but that's something that can be handled when demand is slow and that creates a very nice perceived performance scenario for these kinds of applications. The whole premise of doing BI or doing analysis on data is about reading the data, not updating it, not writing so-called CRUD applications, Create, Read, Update, and Delete. And so this is perfect for NoSQL because we've already seen how they can be difficult to update especially with append-only file systems. But if what you want to do is aggregation or statistical correlation and regressions, you don't need the formal schema that relational databases require of you. You don't even need sophisticated query capabilities because you tend to end up doing a lot of table scans. And you just want to be able to do those as quickly as possible. And, again, it's -- the whole thing about NoSQL is it's typically for applications where the database needs are not especially complex. And as such what you really just need to do is perform operations, oftentimes mathematical ones very, very quickly. And our last topic, the Miscellaneous topic involves pretty much anything that produces log data. And it doesn't have to be a log like a Web log but any system that's going to just keep emitting, you know, little drops of data as things happen. Typically there's very little reason to put that in a relational database and, in fact, most products put this information inside of files. But consider putting it inside of a NoSQL database so that you can do analytics on it later. Things like user profiles and preferences work well in NoSQL databases. You know these are not -- these are not difficult pieces of data to track. If you worked with Windows in the '90s, you may remember any files which were used to store preferences, if you do work with. NET today, I'm sure you're familiar with config files. And the fact is that all of those kind of file-based activities can be kept inside the NoSQL databases very efficiently. Another good application is mail. And, you know, the whole timeline concept that you have in Twitter, storing all those messages and dealing with the streams of them, is something that our data can work on very nicely. And then there's a whole slew of other Web data and I've listed some things here like automobile directions or, you know, the information for different sites in a map. You know just things where, in effect, you have lists of semi-structured data. For automobile directions, it's a list of, you know, of turns and other steps. Things like user reviews, all this kind of stuff that comes up again, a lot, on the Web can work really well in NoSQL databases. And, you know, it's doubtless that that's why Amazon Web Services and Windows Azure have their kind of default catchall structured storage systems geared around NoSQL ideas. So whether it's Amazon SimpleDB or Windows Azure tables, both of those animals work very nicely for some of these, kind of, light data needs. But, again, the data complexity is light, but the data intensity maybe quite high indeed.






What Good is Relational?
Intro and transactional scenarios

This module will juxtapose a bunch of things against what we did in the previous module, where we looked at various places where NoSQL is a killer app.

But just because NoSQL databases work well in specific situations ought not lead you to the idea that relational databases are in some way obsolete or no longer applicable. The reality is that there's still very broad and common situations where relational databases are indispensable.

So, it's important that we kind of reconnect with that reality and understand the NoSQL applicability in context.

So, in this module, we're going to look at about five different qualities or scenarios.

We're going to start by just considering the transactional quality of relational databases and why that's important.

We're then going to talk about formal schema in general and why that is so crucial to so many business computing tasks.

We'll then look at the scenario of line of business applications in general, which is what so much of computing in business is about.

We'll then talk about declarative query as a general quality and why it also is important.

We'll look at the scenario of banded reporting, which is really foundational to the way most operational reporting works.

All of these, really, will underscore why relational is so important.



Transactions
Let's start on the transactional side, and let's just realize that, in general, business systems require atomic transactions.

What an atomic transaction means, in a... simplified kind of explanation, is that it's a system capable of grouping multiple, individual changes to a database into a single indivisible step, so that if any part -- if any one of those operations -- succeeds, then they all must succeed, and if any one of them fails, then they all must fail.

You're not allowed to do part of it. That would leave the database in an inconsistent, invalid state.

Think about this: You can't process an order without decrementing inventory. If you did that, you would then end up selling something to somebody else, when perhaps you did not have sufficient inventory to guarantee that sale. So we need to make sure that when an order is processed, the inventory is decremented, and those two things happen as an indivisible operation. We can't let the order through, if the inventory doesn't decrement, and vice versa.

Another example: Any kind of application involving accounting will have this notion of credits and debits, and it is absolutely not acceptable to commit a credit to the database without also committing the corresponding debit, even if it's a split second between those two. Some other audit process or aggregating process may come into the database and check things in that interim period, even if it is only a split second, and end up -- and end up getting an invalid answer. So we absolutely can't allow that to happen. Again, it's not good enough to be almost. It's not good enough that most of the time this stuff works. It has to work every single time, or else the system really can't be relied upon. It can't be trusted. And thus, it won't be very successful in its application.



Necessity of formal schema, line of business scenarios

Formal schema: Let's talk about this quality, because it, too, is so important. Pretty much any regular business process implicitly relies on the idea of a formal schema, because process is based on the idea that there are specific pieces of information which must always be there; and the structure of that information must be -- must be predictable and repeatable. If we can't have the formal schema, then the process may not work. Think about anything to do with capital markets and stocks and trades. Right? The layout of all of the different attributes of an equity has to be consistent. Now, of course, different types of equities may have different layouts, but then those types are going to be codified, as well. Purchase order line items: These have to be regular, too. Right? It's not -- it's not enough that we can say, well, sometimes we'll have a description, and we'll probably have an amount. I mean, these things are going to be counted. These things are going to be processed. These things emanated from paper forms, and paper forms have a structure that's immutable. The data has to have the same immutable structure, as well. Now, of course, PL line items have actual catalog items in them, and we've already talked about how catalogs can benefit from variable schema, and in fact need that variable schema a lot. But we're not storing the catalog information in the line item. We're merely storing something that uniquely identifies the catalog item, which can then be represented elsewhere, perhaps with variable schema. Personnel records is yet another example of where things have to be consistent. We need to track the same information for all people. We'll probably be in legal jeopardy if we don't. Insurance policies, as well. And the list kind of goes on and on. Right? Again, think -- think about paper forms. And realize that if you were to try and use NoSQL databases for some of these -- for some of these applications really would only work if you kept the schema consistent as a choice. And really, there is no choice. On top of that, the things that NoSQL databases accommodate and end up facilitating aren't especially necessary in these business process scenarios. So, the ability to do MapReduce and the ability to document -- represent things as documents or in graph forms, I mean, these are very elegant, interesting things to do with data, but not things that -- that especially come up in operational systems. Now, of course, we may want to use these -- these representations and MapReduce computation when we analyze the data, after it's been captured in the relational operational system. But at the time of capture, these are not things that are important. In general, line of business applications end up being rooted in the idea of a consistent schema, because if you think about -- if you think about the screens in a line of business application, and you realize that there are fields on the screen and those fields end up being data-bound to particular fields in the database, that -- that's sort of implicitly based on the notion of a declared schema. You can't -- you can't declare the screen design, unless you can also declare the schema. You've got data transfer objects. If you're not a developer and this term's not familiar to you, well, don't worry about it too much. But these are objects that liaise between the application and the database. And we can't have strong typing around data objects, unless we know what the schema is and the types of the different fields in the database. Taking this even further, the whole notion of object-relational mapping is based on the idea that even before the application's written, you create a mapping between the database and the object-oriented pieces of code in your application. If the schema's not there, then you can't map it. It's -- it's just as simple as that.
Importance of declarative query

So, those things really underlie why relational databases are not, you know, merely still useful, but they are absolutely necessary in many cases. Let's talk about the declarative query capabilities of a relational database. Now, if you're going to be doing anything that approaches routine -- or I shouldn't even say routine -- if you're going to do anything that approaches an ad hoc query, or the ability to just ask different questions about your data, the notion that you have to write a procedural program to do that each time is a bit impractical and implies a real hit on productivity. So, ad hoc queries with non-declarative query, with imperative query -- ad hoc -- ad hoc queries in reporting become very difficult. Not only that, but relational databases are very good at sort of understanding what the schema of their databases are and then analyzing a query and building an optimized execution plan, so it can -- it can be -- it can be satisfied very quickly. You lose out on that optimization, you lose out on the versatility of the engine to really adapt to pretty much any kind of query, any kind of question. Given that the -- again, the structure of the database is known, the database can take a whole range of queries and still optimize it. So there's a lot of versatility there, and you kind of lose that. You, in effect, end up having to do the optimization yourself in the code, each time you end up writing an imperative query. Now, if the number of queries your application has to do is limited, then that's fine, because all this optimization work you do is something you kind of do once and you use an awful lot, and that's a fair investment. And in somewhat base systems, this is exactly what's going to happen. I mean, the... queries that you're going to end up needing are very much geared to the user interface of the application. And if there's not a lot of reporting and casual querying of the database, well, then imperative can work very nicely. But if you have, really, any diversity of queries or, you know, if -- put it this way. If the -- if the range of questions about the data is indeterminate, then it really behooves you to have the schema be formal. If the range of questions is limited and well known beforehand, then it becomes a lot easier to allow the schema to be indeterminate and variable. But in business process, you're going to have a range of questions, and you can't -- you can't predict it before the fact. Now, stored procedures -- which virtually every relational database has -- these are -- these are queries stored inside of little programs that can be called. Now, that may seem to set a precedent for, you know, pre-writing your queries, just as you would in an imperative style. But again, if you look at the code inside of a stored procedure, the queries inside it are themselves written declaratively. So, all of the advantages that accrue to declarative query overall also accrue to stored procedures, versus imperative queries written in a MapReduce fashion, or pretty much any other fashion.
Banded reporting

And then we'll finish up with banded reporting. This is the way most operational reporting works. You have a detail section that is repeated for every single row in the -- in the data that you're reporting on. And the section itself is based on a layout. The layout is based on knowing what the schema is in advance and specifying which piece of data goes where. And then the grouping sections around those detail sections work the same way. Now, how are you going to design the report -- especially if it needs to be pixel-perfect, in terms of which data is in which position -- if you don't know what all of that data is? You end up being left in a NoSQL situation. You end up being left where you just say, well, just give me all of the columns and all of the rows, in a kind of tabular fashion. But that ends up being rather generic and not especially helpful. Realize that, again, a lot of these business processes derive from paper forms. Either these are old processes that were once rooted in paper forms, or they're new processes, but you can imagine -- if they existed a while back -- that paper forms would be needed to back them up. Forms -- by the very structure of the word -- are formal. The idea that, you know, forms could have a different structure each time, well, that's not really supported. It's only supported if you kind of have a big area -- a big, blank area -- where people can write things in for special situations, and so forth. But -- but again, that lack of predictability makes it more difficult to automate the process itself. And when you put all of this stuff together, you get to a point where you realize that operational business processes almost always require a relational database. So, relational databases aren't going out of style. They're not merely usable. They are absolutely crucial and necessary to a whole range of software and data-processing scenarios.
NoSQL and Microsoft
Intro, Azure Table Storage, XML columns

I'm Andrew Brust for Pluralsight and this module is NoSQL and Microsoft. The goal with this module is to demonstrate how a conventional software vendor that is essentially in the relational camp, through its stack of products, still makes available and still implements a number of features from the NoSQL approach to processing data. In some cases, actual NoSQL databases themselves are available; but in other cases, elements of the NoSQL approach are available inside of relational technologies. And our goal here is twofold. One is to just show you how prevalent NoSQL ideas and concepts can be; and the other is to demonstrate to you in a tangible way how if certain of those approaches and feature sets appeal to you, to demonstrate to you that you have access to those without having to leave the relational fold. So we're going to look at a range of products from Microsoft starting at the Cloud side and working our way onto the On-Premise side. So we'll look at Azure Table Storage which is as we've said before actually a Key-Value Store. We'll look at XML columns and SQL Server and SQL Azure. We'll look at SQL Azure Federations which is the SQL Azure implementation of the sharding pattern for partitioning your data and we'll have a demo there. We'll look at OData which is Microsoft's open data standard for representing data as XML and processing operations on data through standard Web technologies. We'll look at the option of running MongoDB right on Azure itself. We'll look at something still in its fledgling state and that is Microsoft's adoption of Hadoop on the Windows operating system and on Windows Azure. We'll have a demo there where we actually provision our own cluster and do some Hive queries against some data and even connect to that data from Excel. We'll then talk about so-called Beyond Relational features in SQL Server and how those align with certain NoSQL features and qualities. And we'll finish up with a look at a special version of the SQL Server called the Parallel Data Warehouse Edition. And you'll note that word "parallel" because if you remember back to what we've learned about MapReduce, it's all about taking big queries and chunking them up and executing each of the chunks in a parallel fashion. And we'll see how SQL Server Parallel Data Warehouse does something similar. So let's move on to Azure Table Storage. We've already talked about how this is a Key-Value Store in the Cloud. And although we haven't talked about OData yet, I'll just mention now that this does support the OData interface. So what we have here from Microsoft is a Key-Value Store, a NoSQL store, that provides access through Web standards and represents the data as XML or as indeed as JSON. And if you think back to a demo that we did with CouchDB, you'll remember most of those things were there. Because document databases do have a lot in common with Key-Value Stores, all the data is represented as JSON and everything is done over HTTP and REST which are the standard set of Web technologies. Key-Value Stores work very nicely for general purpose storage and retrieval. And because of the way Microsoft's Azure Cloud works, because additional instances of servers can be spun up or taken down at any time based on demand, which is a good thing by the way, those applications can't rely on things being persistent and staying in memory. So there needs to be a place where applications can store that data temporarily and retrieve it back, and Key-Value Stores work very nicely for that. It's important to note -- this is just kind of a footnote that the precursor to SQL Azure was something that was in beta for its entire lifetime and it was called SQL Server Data Services and it was actually quite similar to Azure Table Storage in terms of the structure. It also was a Key-Value Storage that just happened to use SQL Server as the physical repository for that store. Speaking of which, XML columns in SQL Azure gives us a lot of the niceties of NoSQL databases. That's because XML columns can hold structured data, data that is structured, but that can differ from row to row to row. And what's actually really nice is if you combine kind of conventional scalar columns with XML columns, you end up with the ability to have a core set of data that is consistent from row to row and then the ability to store variable data inside the XML columns. SQL Server gives you some options here that you wouldn't find with a NoSQL database necessarily. Because if you want to, you can actually declare an entire set of XML schemas in a schema collection and apply that to the field. So that still gives you some control, some integrity. Control over what would go in that XML column. But the point is you can have more than one of those. And the other point is you don't have to have any at all. So you can have completely untyped XML. If your motivation in general in using NoSQL is just the idea around loose schema, then you should consider XML columns and consider them very seriously. And if you have any doubt that XML is kind of sufficient to implement NoSQL techniques and operations, think about this; right. The developer version of Windows Azure that runs on the local PC for developer purposes, it's, in effect, an emulator. It also has an emulator for Azure Table Storage. And as it turns out, that emulator is built using XML columns in SQL Server. SQL Server Express which is the free version is what is used in the Dev Fabric. But the point is XML columns are actually used to implement a NoSQL database. So you have very tangible proof that there is a map-ability between these two things.
SQL Azure Federations

So now let's talk about SQL Azure's Federations and recall that this feature is simply SQL Azure's version of the sharding pattern which is the distribution pattern used by most NoSQL databases. Now, in the NoSQL case, sharding is used, both for partitioning the data and also for creating fault tolerance in replication. SQL Azure does give you fault tolerance in replication. It just doesn't do it through the Federations feature. It does it actually in a way that's much more convenient to some, at least, which is that the replication is simply automatic. You don't have to do anything explicit for it to take place. Each database that you put on SQL Azure has two replicas behind it. They're kept up-to-date in realtime and there's nothing special you have to do to make that happen. So, in effect, you have a hot spare ready for any kind of a failure to the infrastructure. Now the way Federations work is that they give you the, I would say, the experience of having explicit objects for partitions of data, but what actually happens is that each of these partitions is, in fact, a physical SQL Azure database. So what you end up having is multiple physical databases but they're put together as a single logical database. And that's why the term is "Federation" because the databases are federated together. But what you end up getting there is the -- you end up getting the sharding pattern across your logical database but you end up getting all the functionality within each partition of an otherwise, you know, relational and unpartitioned SQL Azure database. The way this works is kind of hierarchical. You start with one database that acts as the Federation root. It is both a physical database and, in effect, ends up being the logical database that you address. It defines the Federation Key which is the numeric scheme across which your different partitions will be defined. Within the Federation, you have multiple databases and each one of those is referred to as a Federation member. So the members are physical databases and they hold data for a specific range of values for the Federation Key. Now within members, you have so-called atomic units which are containers for all data with the same Key-Value and you have federated tables within that. As a -- certainly as a user and even as a developer, you don't need to be especially aware or familiar with the root or the unit or the atomic unit or the table. You will have a pretty explicit awareness of Federation Members. And that's kind of it and we'll have a demo in a moment and you'll be able to see all of this and see how it works. And you'll actually see how you take direct control of the members and have a real awareness of them. Federation Members are interesting. They're physical databases which means they can be addressed by name, but they can also be indirectly addressed by saying, Well, I want the database in this Federation that stores data for this particular value of the Federation Key. And I want to use that database. And that lets you explicitly use one of the Federation Members without explicitly naming it. Another thing about Federations is that if you need to take an existing Federation Member and split it into two or take two of them and join them into one because either the volume of your data has increased or the distribution has changed such that one or both of those members has become too small, you can do that and you can do it while the database stays online. Applications don't have to have any awareness of this. They can go ahead and they can query a particular Federation Member while it's being split. What's also neat is that, you know, this is very much a hybrid approach. So although you do have, kind of in the broad scheme of things, you have sharding and therefore, an Eventual Consistency model between the different members, or shards as they're called, when you're in a more purist environment. I'm not talking about SQL Azure specifically. You have an Eventual Consistency between shards but within a particular shard or within a particular Federation Member, you get the ACID guarantees of a relational database because each shard is a relational database. Now, that may strike you as too compromised. You may say well what -- how -- what is really guaranteed if it's only guaranteed sometime -- sometimes? But you have to think about the scenario of the so-called multi-tenancy application where you're creating an application for the Web. You may have lots of customers and you may want the data for all customers to be logically contained within the same repository. But the idea of, kind of, partitioning things so that certain customers are in certain physical databases works out well. And if that's kind of the scope of things, then you can imagine that most queries that you're going to execute are going to take place only across a single Federation Member because it's a multi-tenant application. So in the scope of one tenant in particular, you're probably only going to need to use part of one member to get your work done. So if you can have ACID guarantees there which can really help in terms of the actual, you know, application computation that's going on. But if you can have Eventual Consistency overall which gives you more availability and scale-ability for large multi-tenant scenarios, then you're really in a very nice place. The one major caveat at this time is that Azure Federations do not support fan-out query. So most NoSQL databases do. The fact that you can partition everything is fine. You're going to write MapReduce code; you're going to pull all this data together, and you don't need to be explicitly aware of which data is in which partition. Fine. With Azure Federations, honestly you do. But on the other hand, again, for the multi-tenancy scenario, most likely you're not going to need to query across members. If you do need to query across members, there are lots of techniques you can use on the application site to do that. In the MicrosoftWorld. net, developers can reference each member -- each Federation Member by Key-Value, do their queries across each, and then using a data access object called a data table -- and the ability to fill data tables just depends on what was there before, those individual result sets from each query can be consolidated into a single object, and then treated as, in effect, one sort of larger result set. So that's a lot of theory. Let's now actually take a look at how Federations work.
Demo: SQL Azure Federations

We're now going to do a demo of SQL Azure Federations. And again this is SQL Azure's version of sharding which lets you combine elements of relational and NoSQL models together. Right now, I'm logged into the Windows Azure management portal and what I'm interested in doing is switching over to SQL Azure. To do that, I'm going to click the Database link here at the left. And them I'm going to drill down on Subscriptions and My Subscription and I'm going to click on my Server. That will now enable me to click the Manage button here which is going to bring up the SQL Azure management portal which uses a metro interface and will let us create Federations. What we're going to do here is actually log in. And then we'll be able to create a new database and put a Federation on that database and do some things with it. So here comes my login. And soon enough, we'll be connected. Our first order of business is going to be to create a database and that will be almost as easy as it was in our CouchDB demo from a few modules back. Give it just one moment here and we're in. So notice I have 3 Databases right now. We're interested in creating a 4th. I'll click this button here on the ribbon. We'll just do a small database for now although obviously you wouldn't really even be bothering with Federations unless you had large databases. But for the purposes of a demo, we can do a small one. We'll call the database, "FedTest. " And it will create very quickly. From there, we'll be able to create a Federation. That's what this button here on the right of the ribbon does for us. And we'll let the page paint. There's our page and there comes our new Federation. We're going to call the Federation just simply, "KeyFed" because it's a Federation that we're going to do on the key on the table so "KeyFed. " And then the name of the distribution which is sort of the entity that contains the information for the split, we're going to call that "KeyDist. " We have a choice between various integer types - so bigint, int, unique identifier, and a varbinary. We'll stick with bigint and right now "range" is the only distribution type that exists; i. e. you define it how a distribution splits up or how a Federation splits up amongst its members based on a range of keys. So click Save and that will create the Federation. That will then take us into a summary screen for the database. But our Federation is right down here on the bottom right. And if I scroll over and click on this arrow, now we can sort of see a map of the Federation Members in the Federation. Now remember a Federation Member is a database. And right now we only have 1 because, well, we just began. And we haven't split anything nor could we because we don't even have any data. We don't even have any tables. So let's click on this. Click on Query and then click this option, Create Federated Table. That will give us a T SQL template for creating a table and I'm actually going to use the template as it exists so that's going to sort of do the silly thing of creating a table called, Table 1. But, again, for the purposes of a demo, that should be fine. And notice at the end here, it says it's going to use the distribution we just created and federate this table based on its first column ID. Notice also before any of this create table stuff happens, we tell SQL Server to use "the KeyFed" federation that we just created. That way this table gets created in the context of the federation rather than the physical database called "FedTest. " So we can go ahead and click Run and that table will be created. And then once it is created, I'm going to open up a script that I already have that will just put a couple rows of data in there. Notice I, too, am using the Federation before I do the inserts. I'll click Run. And we'll end up with 2 rows of data in there. ( Pause ) Here it is. And we have our two rows, ID 1 and ID 200. So let's go back now to that map of our Federation Members. And imagine that we have actually a lot more than 2 rows in there. Two is sufficient for me to do a split. It's the minimum required to do a split, but imagine we have many, many more. I'll click Split here and tell it to split on the value of 100 and given what we know about the key values in those 2 rows, that's going to put 1 row in each of the 2 Federation Members because, in effect, 1 member will have rows for everything between 0 and 100, or if we start with negative numbers, it could be a negative number up to 100; and then the 2nd one will be everything above that. We'll click Split. And then once we get control back on this screen, I'm going to click the Refresh button. And once we get control back again, you'll see a little ellipsis button on the Federation Member that will tell us that it's in the process of being split, "Split in progress. " But what's neat about Azure Federation is that even while that's going on, you can query the database. So I'm still able to do this and see Row 1 -- or the row with the ID of 1 and the row with the ID of 100. And if we come back and we hit Refresh here, we should see that the split is still in progress. And we're going to do a quick video pause here and be right back. And we are back. That pause was only about 1 minute. Now we have our 2 Federation Members. Notice this tells us that this Federation begins at the lowest possible value and this one begins at 100. Really I think this should say 99 here, not 100, but we still get the idea; right? It's split at 100 and that's the seam between the 2 members. And, in fact, if we click Query and New Query and we do that Select *, this is on the 1st Federation Member, we're only going to get the one row back with an ID of 1. If we come back here one more time. Click on the 2nd Federation, Query, New Query, paste in our Select * and hit Run there, we'll just get the one row with the ID of 200. So what happens when you have Federations in use is you don't get fan-out support in an implicit way. You need to execute code like this which says to use the Federation and then select the Federation that corresponds to a particular ID that you're interested in and then do your Select * from there. And if you're writing code inside of a client application, then you would know to go through all the Federations that concerned you, select your data, and then put it all together. For example, in. NET, you could put everything together in a table inside of a data set and that would work very nicely. The key, of course, no pun intended, is to engineer the way you're splitting your Federation Members in a multi-tenancy situation so that typically you would only need to query the data in one particular Federation Member because what you would probably be doing is keeping different customers inside of different Federation Members so you probably wouldn't need to select across. But if you did, there are techniques for doing that. And that pretty much finishes up this demo.
OData, MongoDB on Azure, Hadoop on Azure

The next thing to talk about is OData. And when I try to think about how various pieces of technology in the Microsoft stack kind of give us a patchwork of options that kind of resemble what we get with NoSQL, I think of OData and I think of CouchDB and document databases in general and how they're all built around this notion of keeping everything very Web based. And that's what OData is all about. It is a RESTful API for data access. Now RESTful if you're a developer, you know what that means most likely. If you're not, just be aware that that is a relatively convenient way to write code to get at something on using technologies that are very standard on the Web. In effect, the same ones that lots of Web browsers use themselves. And OData can then represent the data as XML or indeed, as JSON, as Java Script Object Notation, which is exactly what we saw CouchDB does in our module called "NoSQL Technology Breakdown. " So, you know, we've already heard about various features in SQL Server and SQL Azure that can give us a NoSQL kind of approach there. And then in terms of having a programming interface, OData gives us something very comparable to what we get in document databases. There are all kinds of client libraries available for OData including JavaScript, which, you know, only furthers the point of virtually all mobile platforms, Android, IOS, as well as Microsoft's own Windows Phone 7 platform have OData clients. And in general, Microsoft's. NET stack and the Java enterprise development stack have it as well. What's nice about OData is that it works not just for getting the feeds of data to read data, but it also works for sending in requests to have that data be created or updated or deleted. And here's a list of all the things in the Microsoft stack and beyond the Microsoft stack that render their own data as OData. So Azure Table Storage which we've already talked about. SQL Server and SQL Azure data can be represented as OData using the thing from whence OData came called WCF Data Services. The Azure DataMarket which is a marketplace for free and fee-based data feeds uses OData as its native format. Reports written using SQL Server Reporting Services in the upcoming version and the most recent version can render all their reports in OData format. SharePoint can do it with its list. And then sort of moving beyond Microsoft, the NetFlix and eBay catalogs are rendered as OData and can be queried that way. Even TwitPic represents its data that way. Even a Microsoft competitor, IBM, with its WebSphere eXtreme Scale data grid has implemented a REST API using OData. And even the humbled Pluralsight catalog can be consumed as an OData feed. So OData is really everywhere. And as I've said before, compare this to the JavaScript and JSON orientation of Document Stores, and combine that with some of the things that you can have in SQL Server, and you see that a lot of what you get in the NoSQL world is, in fact, available in the Microsoft world and you can get at it without having to leave the relational world behind. You can leave the relational world behind if you want to, and, for example, run MongoDB as well as other NoSQL databases on Azure. You -- Azure -- Windows Azure kind of splits its nodes up into Web roles and worker roles. And MongoDB can be deployed out to worker roles. The databases themselves can be stored in Azure Blob Storage which is where binary large objects are stored. And Azure has a nice little trick where it can take a Blob and mount it as if it were a disc drive. And that -- using that trick, MongoDB can actually run very nicely on Azure despite the fact that Azure instances because of their elasticity can be taken down and put up at any time. There is something called the MongoDB Replica Set Azure wrapper. So this is direct and explicit support for MongoDB on Azure. And once your MongoDB database is on Azure, it can then be queried from applications which themselves run on the Cloud as well, or, in fact, application code that runs on-premise infrastructure as well. Just because your database is in the Cloud doesn't mean your application has to be in the Cloud and vice versa. Although that gets a little trickier getting a Cloud application to work with an on-premise database. But all of these things can work together. And then you can take a similar approach, although it requires a little bit more threading of the needle on your own, but you can deploy these packages, these other databases, out to the worker roles and you can also use the Azure Drive Storage technique for making these things run nicely. And then if you really want to go, kind of, whole hog or whole elephant, as it were, you can run Hadoop on Windows, on Windows Azure instances that you control, or you can just go to a portal and provision an entire Hadoop cluster. Now this is still in pre-release form at the time of this recording. It is an invite only community technology preview but luckily I'm in that community technology preview and so we can do a demo of this. Before we do the demo, let's just talk about it a little bit though. So the way this has come about is that a company called HortonWorks, and I'll talk about HortonWorks in a second, but HortonWorks and Microsoft together developed a version of Hadoop that runs on Windows server. Now, HortonWorks is a company made up of people who used to work on the Hadoop team at Yahoo which is really where Hadoop started. So you've got genuine, original, kind of, Hadoop pioneers working on this Azure and Windows version of Hadoop. As I said before, it's in Technology Preview. CTP is another way to refer to that. Now, you can provision a bunch of Azure nodes yourself and then run an installer to create the cluster. You can also do that with on-premise Windows servers. And then the thing that we're go to demo is you can use Hadoop on Azure service to provision an entire cluster right from the portal. In the current CTP that cluster will only last for 48 hours. And so this is something you would typically do, you know, for a specific compute job or group of jobs that could execute within that time. And you actually get a browser-based console for doing Hive queries against your data. You also get a ODBC driver for Hive and that ODBC drive can be used from Excel. And there's actually a full add-in with its own task pane. And it can also be used from PowerPivot, from the upcoming version of Analysis Services in SQL Server in its so-called tabular mode where it uses the same storage engine that PowerPivot uses. And you can even use this ODBC driver from Reporting Services which means that you can do some pretty powerful things with Hive and then the results of the Hive work can then be run off into a Reporting Services report. So let's have a demo of how this works. All right.
Demo: Hadoop On Azure

Well, let's take a look at Microsoft's Apache Hadoop for Windows Azure. Now a disclaimer here is that what you're seeing during this demo is still in a Community Technology Preview. This is not a finally released product in any way. But it should be a good indicator for what will be released in a final form. And what happens is after you log in to the service, if you have not yet set up a cluster, you will be faced with this screen which allows you to provision a cluster and quite easily. You really just have to answer a few questions. First of all, you have to supply a DNS name for, in effect, the head node of the cluster. And for that I'm just going to put in PSDemo as in Pluralsight demo. It tells us that that name is available. This is going to be the full name that points to our node, our working node, I should say, our head node. And then you need to pick a size of the cluster. So you can go all the way up to 32 nodes and 16 terabytes of disk but we can stick with something small, just 4 nodes and 2 terabytes. We then need to put in some credentials. I'm going to put in "abrust" and a password, and I'm going to request my cluster. Now this can take anywhere from a couple of minutes to tens of minutes depending on the size of the cluster and other factors. And we're going to use the magic of time-lapsed videorecording so that you don't need to drum your fingers while we're looking at this. Now, we're not done yet but we can see there's a little progress. Our nodes are listed including our head node down here at the bottom and then our 4 worker nodes - 0, 1, 2, and 3. And notice that the status for all of them is Allocating node. It will stay that way for some time so once again, we're going to use the time lapse trick and be right back. ( Pause ) At this point you can see that 2 of our nodes have shifted in status from "Allocating node" to "Creating node. " And you can see that worker node 0 now has a status of "Starting node" as does worker node 2. And as you can see now, all 5 nodes are "Ready, " but we have a message here that says we're still waiting for the DNS. So we're almost there. And we're back. The cluster is now a 100% allocated and set up. Notice that at this point in time these clusters will only last about 2 days. We're down a few minutes from that already. Now there are a few things here that are worthy of investigation. The first thing is that you'll notice that there is a metro interface so it's a little bit akin to Windows Phone or Windows 8. These actually are live tiles. If we were running a MapReduced job, these live tiles would give us the percentage complete of both the Map -- the Map code and the Reduce code. And we have other managerial tiles here as well. One of them will actually let us Remote Desktop into the head node and we can do that with just a few clicks. This is pretty standard stuff for connecting via Remote Desktop. And here you are. You see that Hadoop on Windows is just that. This is a Windows virtual machine and the Windows implementation of Hadoop has been installed on it. There's even a Hadoop Command Shell. We can go ahead and maximize this. And if we minimize the Remote Desktop window for just a moment, I've got a command here that we can take. And then we'll go back over here to the console and we'll paste it right in. And what this is going to do is it's going to run a Hive QL script that will create a sample hive table with data in it. And I'll show you a few different ways that we can query that table. I'll go ahead and hit Enter and this job will run fairly quickly. What it's going to do is put a bunch of data about cell phones passing towers into a big table for Hive and that table is going to be called Hive Sample Data. If we come back over here to the Web interface to the Azure, notice we have a tile here that says Interactive Console. And this console gives us both a JavaScript console that we can use to run MapReduced jobs. It also gives us an Interactive Hive console. And I'm going to do an extremely simple query here. I'm just going to say, "select * from hivesample" -- I'm not sure if it's hivesampletable or hivesampledata. Let's try hive sample data and we'll say, "limit 10" and we'll go ahead and we'll Evaluate. And what we should see is about 10 rows of data come back from that much larger table. And it maybe that, in fact, it was hivesampletable and not hivesampledata. So let's try it once more. And see if we get a better result. And we did so it's hivesampletable. And notice we're looking at everything kind of formatted as text because hive tables actually are just raw files but we've got a date and time stamp. We've got a language. We've got a make and a model and the location where the tower was that this particular handset passed. Now as neat as it is that we can do queries like this in the browser window and, in fact, we can also do it in that command shell console window that you saw in the remote desktop experience, the Microsoft approach is to actually connect all this stuff back to Microsoft -- Microsoft applications and Microsoft BI technology. If you click on the Downloads tile here, you'll see that there is a 64 bit and a 32 bit msi file for setting up your client machine, the Hive ODBC driver. And what this will also give you is a Hive Add-in for Excel. Now I've already installed that on my machine. The only thing is that by default the port necessary for ODBC to get to your Hadoop cluster is not open and you can visually confirm that for yourself here. Notice it says Open Ports and we see a lock symbol next to ODBC. Well we can easily click that, Click on the slider control and now the ODBC port is open. And let's just double check that. Good. So at this point we should be able to run Excel. This is Excel 2010. And if we click on the Data tab, because I've installed the add-in, I have a little group called Hive Data with a single button that says Hive Pane. Now, in effect, what this does is it gives you an easy gooey for creating what is really an SQL statement and the connection string for going against your Hadoop cluster. Let's take a look at how this works. We'll click Enter Cluster Details and we'll call this PSDemo. The host name, as you may remember, is PSDemo. cloudapp. net. And the user name and password is the one that I configured when I provisioned the cluster in the first place. 10, 000 is the default port. If we come over here, notice it says 10, 000 here as well. So that matches up. And if we click Okay here, there may be just a little bit of a pause. Notice it looks like nothing is happening, but if I click, I'll get the spinner so I know something is happening. And, in effect, we'll be able to do the same query here that we did before. Notice we get a drop-down list of all the tables that are available, hivesampletable being the only one right now. I'll go ahead and click that. And we don't need every single column. Let's just pick the clientid, the market, the deviceplatform, the devicemake, and the devicemodel; and we'll pick state and country as well. Now if we come down here and we look at Limit Rows, et cetera, that's checked off. And the default limit for this little add-in is 200. And here's a preview of the HiveQL query that's going to be generated. Notice it is really just SQL select clientid, market, deviceplatform, devicemake, devicemodel, state, country from hivesampletable 200; and if I click Execute Query, we will soon get the data pushed right into the spreadsheet. And because I had clicked on this LJ7, that's going to end up to be the upper left-hand corner for the table. ( Pause ) And now our data has come in. If we scroll a little bit to the right and down a little bit, we get everything positioned very nicely. Now this same ODBC driver can work inside of PowerPivot. It can work inside of the Tabular Mode of Analysis Services in SQL Server 2012. And it can even work in Reporting Services as well. So what Microsoft has done by putting Hadoop on Windows is not just implementing Hadoop on the Windows operating system, but it has also connected virtually its entire BI stock to this big data platform. And that pretty much finishes out this demo. ( Pause )
SQL Server 'Beyond Relational' and Parallel Data Warehouse

We're almost at the end of our discussion on the Microsoft stack and how it kind of maps to various NoSQL qualities and features and approaches. Let's talk about a couple more pieces of SQL Server that fit under that heading. So there's a whole set of features in SQL Server which Microsoft labels -- which Microsoft labels "Beyond Relational" features. We've already talked about XML Columns. But there's also a feature called HierarchyId which let's you store hierarchical data. If you think back to some of the things we learned about document databases and the fact that documents can store subdocuments, you know, that's obviously a nice way to represent hierarchical data and it turns out SQL Server has its own. SQL Server also has a very intriguing feature called Sparse columns. And Sparse columns are almost like what you get in a Key-Value Store. Or maybe the more appropriate comparison is to what you get in a wide column store. So here's how Sparse columns work. You still have a schema. You still have a schema and you have to declare it. But typically the reason you'll use something like a wide column database is because it's not that you don't know what all your columns are, it's just that you know that in any given row, you're only going to be using some of them. And in other rows, you're going to be using others. And if you had to declare all of them, that would necessarily create a situation where a lot of those columns would be empty in any given row. It would just be depending on the row, different columns would be empty. And that's inefficient. And that's a problem that relational databases have. But Microsoft has solved that problem with the Sparse columns feature. What it lets you do, in effect, is -- specify that although you're going to have certain columns, a bunch of them are only going to occur sometimes. So if that's the case, then what SQL Server says is well, I'm not going to allocate space for every one of those columns on every row. I'm going to make you tell me what those columns are, but I'm only going to take up space for the columns you actually store values in. And therefore and hence the name, Sparse. SQL Server will assume that a bunch of columns will always be empty and it will take measures to avoid the storage inefficiencies that that can create. So although you do have to declare your schema, physically you're getting the same advantage which is that -- which is that columns will only be materialized when they have values. Filestream is something that is somewhat equivalent to the way attachments work in a document database. It's a way to store blobs, store them in the file system, but still have them considered part of the database so that what you don't have to do is put, you know, a file spec in the database and then fetch that file out. You logically -- you logically can look at the files and the blobs as being in the database, but, in fact, they are materialized as files in the file system. Now by combining all of these features including the XML columns that we've already talked about, what this means is that you have all kinds of way to have flexibility in your schema. But while you do that, you don't lose the ACID guarantees. You don't lose transactional capabilities. You don't lose consistency in the database. You gain flexibility but you don't lose the kinds of integrity features that lots and lots of business systems need. And that's why these things can combine to work very nicely in particular applications. The last bit that we're going to look at in this module is SQL Server Parallel Data Warehouse Edition. And that's rather a long thing to say so many of us just say "SQL PDW. " SQL PDW, Parallel Data Warehouse. So this is very interesting because what it does, is it takes a cluster of SQL Servers and it makes them appear as one logical server. And it uses, in order to do this, it uses a technique called Massively Parallel Processing where the query is issued to sort of a head node in the cluster and the head node takes care of splitting that query up and dispatching different parts of it to different particular nodes in the cluster and then it puts -- once each node returns its results, it assembles them back into a single result set. And if you think about that, MPP certainly is working an awful lot like MapReduce. But you still don't have to write imperative code. You're still writing SQL queries and the work of kind of translating that declarative query into the procedural work. The work of kind of doing a map step and a reduce step is something that SQL PDW takes care of for you. So the imperative coding goes away; the declarative query is still there; and fan-out queries are supported unlike in the SQL Azure Federation scenario. Most SQL Server clients will be able to talk to SQL PDW and meanwhile, there's some things to realize. It's only available as an appliance. A lot of SQL Server PDW's performance power comes from a very finely tuned CPU, storage, and networking internals. So this is not something you build yourself. This is something you buy hardware and software together, set it up, give it ping and power, turn it on, and you're ready to go. By the way, SQL Server PDW is certainly not the only product in this category. There are various competing products out there including -- including Teradata, including Netezza which is a product now owned by IBM, Vertica which is now owned by HP. These are some of the MPP products that are out there.
NoSQL, Relational, or Both?
Intro, using type of app as a selection criterion

I'm Andrew Brust for Pluralsight. This module is NoSQL, Relational or Both? This is the final module in our Understanding NoSQL course and as such, our goal here is to take what we've learned and try and distill it down to some rules of thumb and some guidance to help you understand whether adoption of NoSQL in your organization is appropriate, desirable, preferable and compatible. And if so, under what circumstances? In order to do this we're going to look at 3 broad sets of criteria that may govern your decision. We'll talk about the types of applications that you may be building and which ones might lead you to a choice of relational databases or NoSQL databases. We'll look at the whole issue of productivity and make some decisions about that in terms of how it maps to tangible financial impact on the choice of one technology or the other. Along with some of that financial thinking, we're going to look at skill sets and investment that your organization may already have and whether that should be impactful on your decision and to what extent it ought to be. And after looking at those 3 broad criteria categories, we'll distill all that down into a set of recommendations that is as I said before, will be conditional based on exactly the kind of work that you're doing and the nature and culture of your technology organization. So let's talk about type of application as our first category. And as we've seen throughout this course, if we kind of break everything down, if we distill it all, it turns out that in many cases, the choice of relational versus NoSQL comes down to a choice of whether consistency in the database is more important or whether the massive scale is more important. Typically one of these will trump the other. There will be middle ground cases where you can have tolerance around either one and then your choice may be less clear. But I think if we sketch out the extremes, that will help in terms of your own orientation on this. Another way to ask that question is whether you're building an internal system or a public one. Internal systems tend to recommend relational databases. Public ones will certainly give you a much higher likelihood of NoSQL being the correct choice for you. Another way to ask this; this is the third way to ask kind of the same question; and this reads a little bit like a headline or a sub head in an article, but are you building an application in service of a database or are you building a database in service of an application, a system or a web property? Let's take food as an example. If you were building a public site that was focused on food and eating and cooking. If you were going to have all kinds of subject matter related to recipes, interviews with famous chefs, reviews of restaurants and so forth, in that case, what you're really building is a web property. And certainly you need a database to store all the things we were talking about; recipes, reviews and so forth. But in that case, you're really building a database that's a persistence layer in service of a web property. On the other hand if you were building a back office system for food retail operation that needed to track food inventory in warehouses in the supply chain from warehouses to retail locations; if it had to track nutritional information and freshness of the food to maintain compliance with regulations and public health, then you're really maintaining a database and you're building an application to facilitate that database. And if it wasn't already kind of implied, in the former case where you have a site about food and chefs and restaurants, a NoSQL database may work quite well there. It may the better choice. On the other hand for the more operational system, relational database may well be the choice that serves that system best. Almost; in fact almost definitely it will be. Below a certain threshold of concurrent usage, it's important to keep in mind the scalability of NoSQL may not be realized. So don't be so driven by the universal preference for a scaleable system if you're not building a system of the size where that scalability will actually be realized. In fact, NoSQL may actual be slower. And again, we're seeing you know, through various lenses here, that operational systems tend to be best served by relational databases and that public ones that are more kind of content driven tend to be much more served, appropriately served, by a NoSQL database.
Using productivity as a selection criterion

Now let's talk about a set of criteria around productivity. At the beginning this is going to sound very much quite honestly like a manifesto for relational databases but let's take this all the way through before we reach any hasty conclusions. We need to just be mindful; we need to acknowledge that NoSQL databases, many of them, are newer than relational databases. In fact, that's why there's so much interest in them. The big relational databases have been around for as much as 25 years. As such, their tooling is much more mature than the tooling for NoSQL databases. They've had plenty of time to get things right. In fact they've had plenty of times to get things wrong with their tooling and correct them. And in an IT organization where there are going to be a number of routine, menial tasks with a database, and those tasks are going to repeat, the extra productivity that may be provided by better tooling, when multiplied out, when scaled out, across the lifetime of an application and of a business, may end up being quite significant. And that significant in productivity may imply a significant difference in cost. So there may be a real savings to be gained with relational databases. Conversely there may be a real spend in store for people who decide to move to NoSQL without thinking that decision through and considering all facets of what might affect that decision. Queries for a NoSQL database requires significant work and significant testing because you are writing code, especially in the map reduce case. That needs to be considered very seriously. But again, if we go back to the question we just had about whether you're building a system in service of data or database in service of an application or a property, in the latter case, the number of queries will most likely be smaller because the data is not the centerpiece of what you're building. The application is. And if that's the case, then you're going to get added productivity quite frankly out of having a scaleable system and the amount of work required for a relatively small number of queries, is simply going to end up being a good investment rather than an inefficient kind of process. So you really need to consider both sides of the coin when you're asking some of these questions. They may seem leading and leading towards a relational conclusion, but that's not always the case. Now, here's one case where perhaps it is, although in all, these things will be changing. The tooling for NoSQL will get more mature. Right now it's less mature. And also right now, most enterprise development platforms in terms of the languages, the frameworks, the developer components, controls, tend almost automatically to have functionality and compatibility with relational databases built in. It's almost; it's almost an assumed kind of criterion for building these products. So getting things done with relational databases using all kinds of tools for developers will involve a lot less work and a lot less friction. And again, that's especially true in the enterprise. But also consider that this is not a static quality and state of affairs. These are things that change. And also, if you're building an application especially for a new business with a business model that needs to be agile, then the schema for the database for that business may be subject to very frequent and significant change. That actually is something that can be handled in a much more productive way with NoSQL databases. Because relational databases tend to be based on a certain a priory knowledge of what the data is going to look like and then an optimization around that data structure. As such, when data structures change, it can be very disruptive. Whereas NoSQL databases are a lot more flexible.
Using skill sets and investment as selection criteria

Let's talk about skill sets and investment now. And we're going to have a couple of sets of questions here. The first set is going to appear to lead towards a recommendation for relational databases, but I'm going to ask you to suspend judgment on that because some of these questions have a couple of different interpretations and so that may change your judgment about the whole thing. But we have to start with an acknowledgement that our RDBMS skills, relational database skills, are the more well established skill set in general in terms of history. So the question is how old is your organization and how many aggregate years of experience with relational databases do you have? Because that's; that's an asset and assets are things obviously you don't want to squander. You've probably made investment to get those skills and it's a good thing to kind of work through whether you've received the full return on that investment. A further investment might be in the products themselves. In the relational database product licenses and the hardware and the other infrastructure necessary to run them. The number of applications that you've built and that you currently support that use relational databases, are also going to be an important factor in whether or not you adopt NoSQL in your organization. As would be your general willingness to retool and your general willingness to support both groups of technologies. Now, these are not rhetorical questions. It may be that in certain organizations, there's a strong desire to retool. And it may be that the applications you're building going forward will end up having web scale kinds of demands put on them and if that's the case, then as I said, there may be a strong willingness to retool and there may be a strong willingness to support both. There are responsible ways to support both. You may take a strategy where certain of your employees will stay focused on relational technology. New hires may be more focused on NoSQL and some of your existing people may decide to move from one to the other for reasons of, sort of intellectual curiosity or very purposeful desire to develop careers in a slightly different way. Those are all fair, realistic conclusions and judgments. You just need to be very overt about them and very mindful of all of them so that you're not kind of coasting into one decision or the other. Realize that in either case there are going to be costs and that because most companies are not new, the impact of legacy technology skills and applications to consider. Now having said all that, really all of these questions are somewhat premised on being in an enterprise organization. But what if you are a startup company? What if you employ developers who already possess NoSQL skills? And what if they prefer NoSQL? What if there is a cultural preference and a cultural comfort level with NoSQL databases? If you're a younger company with a younger staff, that may well be the case for you. If you're not a younger company and if you have a number of technologists in your organization who have been with you for some years, then there may be a cultural preference going the other way. And cultural preference is important to consider. Not that you ought to be bullied by that kind of; by that kind of criteria and that kind of outcome. But you do need to consider morale and the impact of morale on productivity, which can be quite high. There may be cost savings involved in making a decision that will be popular and have a lot of buy in. Again, that doesn't mean you should succumb to peer pressure. This is a business decision, but one factor in the business decision is going to be the popularity amongst your technologists for the decision that you've made. And of course that's a popularity over time that you have to consider, not just the immediate popularity or appearance of popularity. And it may also be that the availability and scalability questions, especially for startups, make those first 5 questions up on top of the slide, somewhat irrelevant or somewhat moot. I suppose another way of looking at that is that the last 2 of those 5 questions, the do you want to retool and do you want to support both; it may lead to emphatic yeses as answers to both of those. So again, really all of these questions can very much end up with different answers depending on the type of organization and the business priorities for that organization in terms of what kind of technology they want to build and need to build.
Summarized recommendations

Let's finish up now with some conditional recommendations. And we'll start with a couple of examples that are really at either one extreme or the other, fully realizing that many applications may not be at the extremes, but we need to at least to define the extremes. And so we'll start with large, public, content- centric properties. And these tend to be best served by NoSQL databases. On the other hand, internal line of business applications that are supporting business operations, very often will be best served by relational databases and in point of fact, may be served exclusively by relational databases. Now of course many applications will fall in the middle of that spectrum. So then you need to think about things like your investment in licenses. in infrastructure, in skills. And based on what that investment may be, that will most likely, unless it's 0; that will most likely lead you to a choice of sticking with relational exclusively, of using both and picking one or the other depending on the application, or quite possibly, sticking with relational databases but using some of the features that are more NoSQL oriented in terms of their capability and we saw many examples of this as we have looked through Microsoft's stack, which was just used as an example. Other stacks have similar kinds of influences from NoSQL technology. So very likely, you're going to be somewhere in the middle and it may be quite appropriate to use either a hybrid approach or a combined approach. Think about cost-benefit analysis as well. The productivity will tend to drive that cost-benefit analysis, but remember that can really work either way. So how much extra development time and money will be required if you work with a NoSQL database? Conversely, how much extra dev time and investment in terms of money, will be required if you don't move from relational. Because depending on the type of application, you may have to work quite hard to get a relational database to continue to serve your applications if they're really changing in nature and becoming you know larger, more public and more content-centric. What is the cost of a system that is less scaleable? And remember that the scalability of the system is not universally best served by one or the other. It really depends on whether a certain threshold has been crossed in terms of the size of the user base. It's important to pick the right database technology for the job. We've gone in quite some detail now, about which types of applications will be best served by which type of database. Having said all that, it's also possible to make the wrong choice. It's possible to pick NoSQL because it's new and there's quite a lot of popularity around it. It may be tempting to pick relational even when that's not the right choice, simply because it's older and more familiar. And it may be possible that if you make the wrong decision, that you'll be able to get that particular database technology to work in its first application even if it wasn't the right choice. Because really, any problem is computable or implementable in any system given enough time and enough effort. But that would be a false validation, and so you need to be especially sober and objective and methodical when you make your decision here. Hopefully the material that we've covered in this course, and the less obvious questions that we've gotten to by deconstructing some of the facets of these technologies, will make it easier to make a better decision and a better informed decision. We certainly hope so. We certainly hope that we've helped.
